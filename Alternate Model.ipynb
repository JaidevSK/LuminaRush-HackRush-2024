{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN4yVFK5-0Bf",
        "outputId": "bf4a899c-0259-4ae8-b312-90cade3d5629"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/242.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -q tensorflow\n",
        "! pip install -q tensorflow-model-optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yJwIonXEVJo6"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow_model_optimization.python.core.keras.compat import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psViY5PRDurp"
      },
      "source": [
        "# CIFAR 10 without quantization aware training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbY-KGMPvbW9",
        "outputId": "c559691f-e18c-4204-bfa8-d02cb2fbca88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n",
            "1407/1407 [==============================] - 23s 6ms/step - loss: 1.5031 - accuracy: 0.4521 - val_loss: 1.2033 - val_accuracy: 0.5728\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x79f500496200>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load CIFAR 10 dataset\n",
        "cifar = tf.keras.datasets.cifar10\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model architecture.\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dense(10)  # Output layer with 10 classes\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNK_DoxdZYqd",
        "outputId": "260f08f7-7e25-437f-83fd-9b1f2bab3f7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1112 - accuracy: 0.9623 - val_loss: 2.1090 - val_accuracy: 0.7124\n",
            "Epoch 2/10\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.1156 - accuracy: 0.9608 - val_loss: 2.1206 - val_accuracy: 0.7142\n",
            "Epoch 3/10\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 0.1003 - accuracy: 0.9661 - val_loss: 2.2440 - val_accuracy: 0.6942\n",
            "Epoch 4/10\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1137 - accuracy: 0.9623 - val_loss: 2.1396 - val_accuracy: 0.7084\n",
            "Epoch 5/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.0987 - accuracy: 0.9663 - val_loss: 2.2766 - val_accuracy: 0.6998\n",
            "Epoch 6/10\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1056 - accuracy: 0.9652 - val_loss: 2.2273 - val_accuracy: 0.7058\n",
            "Epoch 7/10\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0936 - accuracy: 0.9687 - val_loss: 2.3879 - val_accuracy: 0.7134\n",
            "Epoch 8/10\n",
            "1407/1407 [==============================] - 6s 5ms/step - loss: 0.1045 - accuracy: 0.9650 - val_loss: 2.3126 - val_accuracy: 0.7100\n",
            "Epoch 9/10\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1036 - accuracy: 0.9657 - val_loss: 2.3632 - val_accuracy: 0.7104\n",
            "Epoch 10/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.0978 - accuracy: 0.9675 - val_loss: 2.5192 - val_accuracy: 0.6996\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x79f52ac60160>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  validation_split=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8747K9OE72P"
      },
      "source": [
        "## Clone and fine-tune pre-trained model with quantization aware training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq6blGjgFDCW",
        "outputId": "0ed8c59d-d4f1-4024-cd0d-40429bda1432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer_1 (Quantize  (None, 32, 32, 3)         3         \n",
            " Layer)                                                          \n",
            "                                                                 \n",
            " quant_conv2d_3 (QuantizeWr  (None, 30, 30, 32)        963       \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_max_pooling2d_3 (Qua  (None, 15, 15, 32)        1         \n",
            " ntizeWrapperV2)                                                 \n",
            "                                                                 \n",
            " quant_conv2d_4 (QuantizeWr  (None, 13, 13, 64)        18627     \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_max_pooling2d_4 (Qua  (None, 6, 6, 64)          1         \n",
            " ntizeWrapperV2)                                                 \n",
            "                                                                 \n",
            " quant_conv2d_5 (QuantizeWr  (None, 4, 4, 128)         74115     \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_max_pooling2d_5 (Qua  (None, 2, 2, 128)         1         \n",
            " ntizeWrapperV2)                                                 \n",
            "                                                                 \n",
            " quant_flatten_1 (QuantizeW  (None, 512)               1         \n",
            " rapperV2)                                                       \n",
            "                                                                 \n",
            " quant_dense_2 (QuantizeWra  (None, 256)               131333    \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_dense_3 (QuantizeWra  (None, 10)                2575      \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 227620 (889.14 KB)\n",
            "Trainable params: 227146 (887.29 KB)\n",
            "Non-trainable params: 474 (1.85 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# q_aware stands for for quantization aware.\n",
        "q_aware_model = quantize_model(model)\n",
        "\n",
        "# `quantize_model` requires a recompile.\n",
        "q_aware_model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "q_aware_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDr2ijwpGCI-"
      },
      "source": [
        "### Train and evaluate the model against baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUBEn94hXYB1"
      },
      "source": [
        "To demonstrate fine tuning after training the model for just an epoch, fine tune with quantization aware training on a subset of the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PHDGJryE31X",
        "outputId": "97eba051-8516-4a5b-a4db-a8ff6684c4dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "50/50 [==============================] - 10s 66ms/step - loss: 0.2568 - accuracy: 0.9272 - val_loss: 1.7764 - val_accuracy: 0.6900\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.1477 - accuracy: 0.9681 - val_loss: 1.8825 - val_accuracy: 0.7000\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.1123 - accuracy: 0.9768 - val_loss: 1.9695 - val_accuracy: 0.7080\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0858 - accuracy: 0.9832 - val_loss: 1.9914 - val_accuracy: 0.7140\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0640 - accuracy: 0.9883 - val_loss: 1.9412 - val_accuracy: 0.7140\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0490 - accuracy: 0.9909 - val_loss: 2.0309 - val_accuracy: 0.7200\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0370 - accuracy: 0.9934 - val_loss: 2.0650 - val_accuracy: 0.7160\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0268 - accuracy: 0.9954 - val_loss: 2.1376 - val_accuracy: 0.7220\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0200 - accuracy: 0.9970 - val_loss: 2.1482 - val_accuracy: 0.7080\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0142 - accuracy: 0.9981 - val_loss: 2.2721 - val_accuracy: 0.6960\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0096 - accuracy: 0.9991 - val_loss: 2.3719 - val_accuracy: 0.7080\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0073 - accuracy: 0.9996 - val_loss: 2.4157 - val_accuracy: 0.7120\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 2.4972 - val_accuracy: 0.7080\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 2.5160 - val_accuracy: 0.7100\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 2.5406 - val_accuracy: 0.7100\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 2.5883 - val_accuracy: 0.7140\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 2.6484 - val_accuracy: 0.7020\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 2.6147 - val_accuracy: 0.7180\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6999 - val_accuracy: 0.7060\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.7320 - val_accuracy: 0.7060\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 9.5608e-04 - accuracy: 1.0000 - val_loss: 2.7506 - val_accuracy: 0.7080\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 8.5044e-04 - accuracy: 1.0000 - val_loss: 2.7665 - val_accuracy: 0.7080\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 7.7031e-04 - accuracy: 1.0000 - val_loss: 2.7881 - val_accuracy: 0.7100\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 6.8299e-04 - accuracy: 1.0000 - val_loss: 2.8018 - val_accuracy: 0.7080\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 6.2865e-04 - accuracy: 1.0000 - val_loss: 2.8190 - val_accuracy: 0.7120\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 5.7769e-04 - accuracy: 1.0000 - val_loss: 2.8463 - val_accuracy: 0.7100\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 5.3536e-04 - accuracy: 1.0000 - val_loss: 2.8941 - val_accuracy: 0.7100\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 4.9793e-04 - accuracy: 1.0000 - val_loss: 2.8977 - val_accuracy: 0.7080\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 4.5786e-04 - accuracy: 1.0000 - val_loss: 2.8895 - val_accuracy: 0.7120\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 4.3227e-04 - accuracy: 1.0000 - val_loss: 2.9239 - val_accuracy: 0.7160\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 4.0170e-04 - accuracy: 1.0000 - val_loss: 2.9527 - val_accuracy: 0.7120\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 3.7573e-04 - accuracy: 1.0000 - val_loss: 2.9421 - val_accuracy: 0.7140\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 3.5763e-04 - accuracy: 1.0000 - val_loss: 2.9874 - val_accuracy: 0.7160\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 3.3159e-04 - accuracy: 1.0000 - val_loss: 2.9990 - val_accuracy: 0.7140\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 3.1711e-04 - accuracy: 1.0000 - val_loss: 3.0154 - val_accuracy: 0.7120\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 3.0203e-04 - accuracy: 1.0000 - val_loss: 3.0173 - val_accuracy: 0.7100\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 2.8213e-04 - accuracy: 1.0000 - val_loss: 3.0410 - val_accuracy: 0.7080\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 2.6784e-04 - accuracy: 1.0000 - val_loss: 3.0412 - val_accuracy: 0.7160\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 2.5532e-04 - accuracy: 1.0000 - val_loss: 3.0589 - val_accuracy: 0.7120\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 2.3552e-04 - accuracy: 1.0000 - val_loss: 3.0957 - val_accuracy: 0.7100\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 2.2729e-04 - accuracy: 1.0000 - val_loss: 3.1078 - val_accuracy: 0.7080\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 2.1724e-04 - accuracy: 1.0000 - val_loss: 3.1146 - val_accuracy: 0.7100\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 2.0654e-04 - accuracy: 1.0000 - val_loss: 3.1141 - val_accuracy: 0.7160\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 1.9658e-04 - accuracy: 1.0000 - val_loss: 3.1420 - val_accuracy: 0.7140\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 1.8862e-04 - accuracy: 1.0000 - val_loss: 3.1555 - val_accuracy: 0.7100\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 1.8058e-04 - accuracy: 1.0000 - val_loss: 3.1706 - val_accuracy: 0.7140\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 1.7428e-04 - accuracy: 1.0000 - val_loss: 3.1983 - val_accuracy: 0.7080\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 1.6227e-04 - accuracy: 1.0000 - val_loss: 3.2002 - val_accuracy: 0.7080\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.5773e-04 - accuracy: 1.0000 - val_loss: 3.2031 - val_accuracy: 0.7140\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 1.4836e-04 - accuracy: 1.0000 - val_loss: 3.2213 - val_accuracy: 0.7160\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x79f52adcbe20>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images_subset = train_images[0:60000] # out of 60000\n",
        "train_labels_subset = train_labels[0:60000]\n",
        "\n",
        "q_aware_model.fit(train_images_subset, train_labels_subset,\n",
        "                  batch_size=1000, epochs=50, validation_split=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-byC2lYlMkfN"
      },
      "source": [
        "For this example, there is minimal to no loss in test accuracy after quantization aware training, compared to the baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bMFTKSSHyyZ",
        "outputId": "2292d3db-1444-4857-e62d-3beb21c2a97c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline test accuracy: 0.6876999735832214\n",
            "Quant test accuracy: 0.7235999703407288\n"
          ]
        }
      ],
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "_, q_aware_model_accuracy = q_aware_model.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Quant test accuracy:', q_aware_model_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7fztWsAOHTz",
        "outputId": "3ce8a36f-f131-4a4b-a23f-ef8706a915e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4LqXysXLd7RZ"
      },
      "outputs": [],
      "source": [
        "# Save the converted model to a file\n",
        "with open('NewQNNmodel.tflite', 'wb') as f:\n",
        "    f.write(quantized_tflite_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy_Lgfh8VkyX",
        "outputId": "ae88a2c2-d595-4f63-ba7b-6d2553c876b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Float model in Mb: 0.8702888488769531\n",
            "Quantized model in Mb: 0.2286376953125\n"
          ]
        }
      ],
      "source": [
        "# Create float TFLite model.\n",
        "float_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "float_tflite_model = float_converter.convert()\n",
        "\n",
        "# Measure sizes of models.\n",
        "_, float_file = tempfile.mkstemp('.tflite')\n",
        "_, quant_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(quant_file, 'wb') as f:\n",
        "  f.write(quantized_tflite_model)\n",
        "\n",
        "with open(float_file, 'wb') as f:\n",
        "  f.write(float_tflite_model)\n",
        "\n",
        "print(\"Float model in Mb:\", os.path.getsize(float_file) / float(2**20))\n",
        "print(\"Quantized model in Mb:\", os.path.getsize(quant_file) / float(2**20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IJzCFOzgCxe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "training_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
